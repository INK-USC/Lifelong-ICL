{"text": "Our << acquisition program - LEXICALL - >> takes , as input , the result of previous work on [[ verb classification ]] and thematic grid tagging , and outputs LCS representations for different languages .", "label": "Used For", "id": "train_3_0"}
{"text": "We also propose an efficient eigenvector solver which not only reduces the computational cost of << spectral clustering >> by many folds but also improves the [[ clustering quality ]] and final classification results .", "label": "Evaluate For", "id": "train_3_1"}
{"text": "Later , however , Breiman cast serious doubt on this explanation by introducing a boosting algorithm , [[ arc-gv ]] , that can generate a higher margins distribution than << AdaBoost >> and yet performs worse .", "label": "Compare", "id": "train_3_2"}
{"text": "[[ Spelling-checkers ]] have become an integral part of most << text processing software >> .", "label": "Part Of", "id": "train_3_3"}
{"text": "The network is trained using a << large-margin objective >> that combines cross-view ranking constraints with [[ within-view neighborhood structure preservation constraints ]] inspired by metric learning literature .", "label": "Feature Of", "id": "train_3_4"}
{"text": "Input to the NLP system is typically derived from an existing << electronic message stream >> , such as a [[ news wire ]] .", "label": "Hypohym Of", "id": "train_3_5"}
{"text": "Comprehensive evaluation is performed on a variety of challenging non-rigid surfaces including [[ face ]] , << cloth >> and people .", "label": "Conjunction", "id": "train_3_6"}
{"text": "The model acts as an interlingua within a new multi-pathway MT architecture design that also incorporates transfer and [[ direct approaches ]] into a single << system >> .", "label": "Part Of", "id": "train_3_7"}
{"text": "Experiments show that the efficiency of the overall analysis improves significantly and that our << system >> also provides robustness to the linguistic processing while maintaining both the [[ accuracy ]] and the precision of the grammar .", "label": "Evaluate For", "id": "train_3_8"}
{"text": "To overcome this limitation , we propose a novel mapping algorithm that derives the relative positioning and [[ orientation ]] between two << PTZ cameras >> based on a unified polynomial model .", "label": "Feature Of", "id": "train_3_9"}
{"text": "Using our [[ approach ]] we are able to intelligently segment scenes with objects of greater complexity than previous << physics-based segmentation algorithms >> .", "label": "Compare", "id": "train_3_10"}
{"text": "One of the main results of this work is the definition of a relation between [[ broad semantic classes ]] and << LCS meaning components >> .", "label": "Conjunction", "id": "train_3_11"}
{"text": "The suggested [[ approach ]] combines multiple cues , i.e. , positions , velocities and appearance into both the << learning and detection phases >> .", "label": "Used For", "id": "train_3_12"}
{"text": "The system participated in all the tracks of the << segmentation bakeoff >> -- PK-open , PK-closed , AS-open , AS-closed , [[ HK-open ]] , HK-closed , MSR-open and MSR - closed -- and achieved the state-of-the-art performance in MSR-open , MSR-close and PK-open tracks .", "label": "Hypohym Of", "id": "train_3_13"}
{"text": "In contrast to existing [[ methods ]] that consider only the guidance image , our << method >> can selectively transfer salient structures that are consistent in both guidance and target images .", "label": "Compare", "id": "train_3_14"}
{"text": "Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall , achieving a [[ relative error rate reduction ]] of 6.56 % as compared with the << state-of-the-art technologies >> .", "label": "Evaluate For", "id": "train_3_15"}
{"text": "Sentence planning is a set of inter-related but distinct << tasks >> , one of which is [[ sentence scoping ]] , i.e. the choice of syntactic structure for elementary speech acts and the decision of how to combine them into one or more sentences .", "label": "Part Of", "id": "train_3_16"}
{"text": "Unfortunately , such estimates would typically require the relations -LRB- scale factors -RRB- between the [[ frequency components ]] and the << speed >> for different gears to be known .", "label": "Conjunction", "id": "train_3_17"}
{"text": "Specifically , we formulate the << conjugate prior >> in the form of [[ Bregman divergence ]] and show that it is the inherent geometry of conjugate priors that makes them appropriate and intuitive .", "label": "Feature Of", "id": "train_3_18"}
{"text": "Ideally , these are basic vocabulary units suitable for different << tasks >> , such as [[ speech and text understanding ]] , machine translation , information retrieval , and statistical language modeling .", "label": "Hypohym Of", "id": "train_3_19"}
{"text": "A novel [[ bootstrapping approach ]] to << Named Entity -LRB- NE -RRB- tagging >> using concept-based seeds and successive learners is presented .", "label": "Used For", "id": "train_3_20"}
{"text": "Experimental results show that our << method >> has permitted autonomous , stable and effective [[ information integration ]] to construct the internal model of hierarchical perceptual sounds .", "label": "Feature Of", "id": "train_3_21"}
{"text": "However , for grammar formalisms which use more << fine-grained grammatical categories >> , for example tag and [[ ccg ]] , tagging accuracy is much lower .", "label": "Hypohym Of", "id": "train_3_22"}
{"text": "While such decoding is an essential underpinning , much recent work suggests that natural language interfaces will never appear cooperative or graceful unless << they >> also incorporate numerous [[ non-literal aspects of communication ]] , such as robust communication procedures .", "label": "Part Of", "id": "train_3_23"}
{"text": "The << compact description of a video sequence >> through a single image map and a [[ dominant motion ]] has applications in several domains , including video browsing and retrieval , compression , mosaicing , and visual summarization .", "label": "Used For", "id": "train_3_24"}
{"text": "Experiments show that the learned [[ tracker ]] performs much better than existing << trackers >> on the tracking of complex non-rigid motions such as fish twisting with self-occlusion and large inter-frame lip motion .", "label": "Compare", "id": "train_3_25"}
{"text": "The compact description of a video sequence through a single [[ image map ]] and a << dominant motion >> has applications in several domains , including video browsing and retrieval , compression , mosaicing , and visual summarization .", "label": "Conjunction", "id": "train_3_26"}
{"text": "The accuracy of the << tensor method >> is verified with [[ computer-generated sequences ]] and a calibrated image sequence .", "label": "Evaluate For", "id": "train_3_27"}
{"text": "These << constraints >> are of two types : [[ conditional inde-pendencies ]] and algebraic constraints , first noted by Verma .", "label": "Hypohym Of", "id": "train_3_28"}
{"text": "The results of the experiments demonstrate that the [[ HDAG Kernel ]] is superior to other << kernel functions >> and baseline methods .", "label": "Compare", "id": "train_3_29"}
{"text": "This paper presents an analysis of << temporal anaphora >> in sentences which contain [[ quantification over events ]] , within the framework of Discourse Representation Theory .", "label": "Part Of", "id": "train_3_30"}
{"text": "We describe the ongoing construction of a large , [[ semantically annotated corpus ]] resource as reliable basis for the << large-scale acquisition of word-semantic information >> , e.g. the construction of domain-independent lexica .", "label": "Used For", "id": "train_3_31"}
{"text": "Numerical tests on [[ large-scale logistic regression problems ]] reveal that our << method >> is more robust and substantially outperforms current state-of-the-art methods .", "label": "Evaluate For", "id": "train_3_32"}
{"text": "<< Polymorphemic stems >> not explicitly stored in the lexicon are given a [[ compositional interpretation ]] .", "label": "Feature Of", "id": "train_3_33"}
{"text": "This system consists of one or more [[ reference times ]] and << temporal perspective times >> , the speech time and the location time .", "label": "Conjunction", "id": "train_3_34"}
{"text": "This paper focuses on the automatic summarization and proposes two different models to extract sentences for summary generation under two [[ tasks ]] initiated by << SUMMAC-1 >> .", "label": "Part Of", "id": "train_3_35"}
{"text": "We present the first known empirical test of an increasingly common speculative claim , by evaluating a representative << Chinese-to-English SMT model >> directly on word sense disambiguation performance , using standard WSD evaluation methodology and datasets from the [[ Senseval-3 Chinese lexical sample task ]] .", "label": "Evaluate For", "id": "train_3_36"}
{"text": "This paper proposes an automatic , essentially domain-independent means of evaluating Spoken Language Systems -LRB- SLS -RRB- which combines [[ software ]] we have developed for that purpose -LRB- the '' Comparator '' -RRB- and a set of << specifications >> for answer expressions -LRB- the '' Common Answer Specification '' , or CAS -RRB- .", "label": "Conjunction", "id": "train_3_37"}
{"text": "We show that the newly proposed concept-distance measures outperform traditional distributional word-distance measures in the << tasks >> of -LRB- 1 -RRB- [[ ranking word pairs in order of semantic distance ]] , and -LRB- 2 -RRB- correcting real-word spelling errors .", "label": "Hypohym Of", "id": "train_3_38"}
{"text": "We describe the use of [[ text data ]] scraped from the web to augment << language models >> for Automatic Speech Recognition and Keyword Search for Low Resource Languages .", "label": "Used For", "id": "train_3_39"}
{"text": "We provide a detailed preliminary analysis of << inter-annotator agreement >> - both the level of agreement and the types of [[ inter-annotator variation ]] .", "label": "Feature Of", "id": "train_3_40"}
{"text": "When a constraint is amenable to short supports , the [[ short support set ]] can be exponentially smaller than the << full-length support set >> .", "label": "Compare", "id": "train_3_41"}
{"text": "The [[ model ]] gives an F-measure improvement of ~ 1.25 % beyond the << base parser >> , and an ~ 0.25 % improvement beyond Collins -LRB- 2000 -RRB- reranker .", "label": "Compare", "id": "train_3_42"}
{"text": "Specifically , the following << components >> of the system are described : the syntactic analyzer , based on a Procedural Systemic Grammar , the semantic analyzer relying on the Conceptual Dependency Theory , and the [[ dictionary ]] .", "label": "Part Of", "id": "train_3_43"}
{"text": "In this paper , we propose a feasible process of such a transfer , comparing the possibilities the Praguian dependency-based approach offers with the << Penn discourse annotation >> based primarily on the [[ analysis and classification of discourse connectives ]] .", "label": "Evaluate For", "id": "train_3_44"}
{"text": "We investigate the utility of an algorithm for translation lexicon acquisition -LRB- SABLE -RRB- , used previously on a very large corpus to acquire general translation lexicons , when that [[ algorithm ]] is applied to a much smaller corpus to produce candidates for << domain-specific translation lexicons >> .", "label": "Used For", "id": "train_3_45"}
{"text": "We present two methods for capturing nonstationary chaos , then present a few examples including [[ biological signals ]] , << ocean waves >> and traffic flow .", "label": "Conjunction", "id": "train_3_46"}
{"text": "Experiments show that the learned tracker performs much better than existing trackers on the tracking of complex non-rigid motions such as << fish twisting >> with self-occlusion and large [[ inter-frame lip motion ]] .", "label": "Feature Of", "id": "train_3_47"}
{"text": "Extensive experiments show that our method works satisfactorily on challenging image data , which establishes a technical foundation for solving several << computer vision problems >> , such as [[ motion analysis ]] and image restoration , using the blur information .", "label": "Hypohym Of", "id": "train_3_48"}
{"text": "The experimental results will show that [[ it ]] significantly outperforms state-of-the-art << approaches >> in sentence-level correlation .", "label": "Compare", "id": "train_3_49"}
{"text": "We describe << three techniques >> for making syntactic analysis more robust -- an [[ agenda-based scheduling parser ]] , a recovery technique for failed parses , and a new technique called terminal substring parsing .", "label": "Hypohym Of", "id": "train_3_50"}
{"text": "The proposed << technique >> operates on [[ syntactically shallow-parsed corpora ]] on the basis of a limited number of search heuristics not relying on any previous lexico-syntactic knowledge about SCFs .", "label": "Used For", "id": "train_3_51"}
{"text": "The proposed << mechanism >> includes title-driven name recognition , [[ adaptive dynamic word formation ]] , identification of 2-character and 3-character Chinese names without title .", "label": "Part Of", "id": "train_3_52"}
{"text": "This paper proposes that sentence analysis should be treated as defeasible reasoning , and presents such a treatment for Japanese sentence analyses using an argumentation system by Konolige , which is a formalization of defeasible reasoning , that includes << arguments >> and defeat rules that capture [[ defeasibility ]] .", "label": "Feature Of", "id": "train_3_53"}
{"text": "Our approach yields [[ phrasal and single word lexical paraphrases ]] as well as << syntactic paraphrases >> .", "label": "Conjunction", "id": "train_3_54"}
{"text": "Over the last decade , a variety of SMT algorithms have been built and empirically tested whereas little is known about the [[ computational complexity ]] of some of the fundamental << problems >> of SMT .", "label": "Evaluate For", "id": "train_3_55"}
{"text": "The [[ transfer phase ]] in << machine translation -LRB- MT -RRB- systems >> has been considered to be more complicated than analysis and generation , since it is inherently a conglomeration of individual lexical rules .", "label": "Part Of", "id": "train_3_56"}
{"text": "The model will represent the language proficiency of the user and is designed to be referenced during both [[ writing analysis ]] and << feedback production >> .", "label": "Conjunction", "id": "train_3_57"}
{"text": "Effectiveness of the proposed << framework >> was confirmed in the [[ success rate of retrieval ]] and the average number of turns for information access .", "label": "Evaluate For", "id": "train_3_58"}
{"text": "This paper defines a << generative probabilistic model of parse trees >> , which we call [[ PCFG-LA ]] .", "label": "Hypohym Of", "id": "train_3_59"}
{"text": "However most of the works found in the literature have focused on identifying and understanding << temporal expressions >> in [[ newswire texts ]] .", "label": "Feature Of", "id": "train_3_60"}
{"text": "Ideally , [[ these ]] are basic vocabulary units suitable for different << tasks >> , such as speech and text understanding , machine translation , information retrieval , and statistical language modeling .", "label": "Used For", "id": "train_3_61"}
{"text": "Extensive experiments on two tasks have demonstrated the superiority of our [[ method ]] over the << state-of-the-art methods >> .", "label": "Compare", "id": "train_3_62"}
{"text": "Each << generalized metaphor >> contains a recognition network , a [[ basic mapping ]] , additional transfer mappings , and an implicit intention component .", "label": "Part Of", "id": "train_3_63"}
{"text": "A method of sense resolution is proposed that is based on WordNet , an on-line lexical database that incorporates semantic relations -LRB- [[ synonymy ]] , << antonymy >> , hyponymy , meronymy , causal and troponymic entailment -RRB- as labeled pointers between word senses .", "label": "Conjunction", "id": "train_3_64"}
{"text": "Experiments evaluating the effectiveness of our << answer resolution algorithm >> show a 35.0 % relative improvement over our baseline system in the number of questions correctly answered , and a 32.8 % improvement according to the [[ average precision metric ]] .", "label": "Evaluate For", "id": "train_3_65"}
{"text": "The use of BLEU at the character level eliminates the word segmentation problem : it makes it possible to directly compare [[ commercial systems ]] outputting unsegmented texts with , for instance , << statistical MT systems >> which usually segment their outputs .", "label": "Compare", "id": "train_3_66"}
{"text": "Using [[ natural language processing ]] , we carried out a << trend survey on Japanese natural language processing studies >> that have been done over the last ten years .", "label": "Used For", "id": "train_3_67"}
{"text": "We show that the suggested hybrid proba-bilistic model -LRB- which combines global variables , like translation , with local variables , like relative positions and appearances of body parts -RRB- , leads to : -LRB- i -RRB- [[ faster convergence ]] of << learning phase >> , -LRB- ii -RRB- robustness to occlusions , and , -LRB- iii -RRB- higher recognition rate .", "label": "Feature Of", "id": "train_3_68"}
{"text": "We show that the suggested hybrid proba-bilistic model -LRB- which combines global variables , like translation , with << local variables >> , like [[ relative positions ]] and appearances of body parts -RRB- , leads to : -LRB- i -RRB- faster convergence of learning phase , -LRB- ii -RRB- robustness to occlusions , and , -LRB- iii -RRB- higher recognition rate .", "label": "Hypohym Of", "id": "train_3_69"}
{"text": "Experimental results show that our << approach >> improves domain-specific word alignment in terms of both [[ precision ]] and recall , achieving a relative error rate reduction of 6.56 % as compared with the state-of-the-art technologies .", "label": "Evaluate For", "id": "train_3_70"}
{"text": "We show that the << model >> trained on a certain type of [[ data ]] , e.g. , RGB and depth images , generalizes well for other modalities , e.g. , Flash/Non-Flash and RGB/NIR images .", "label": "Used For", "id": "train_3_71"}
{"text": "We detail the [[ computational complexity ]] and << average retrieval times >> for looking up phrase translations in our suffix array-based data structure .", "label": "Conjunction", "id": "train_3_72"}
{"text": "We introduced a new << linguistic representation >> , the [[ Dynamic Hierarchical Phrasal Lexicon -LRB- DHPL -RRB- ]] -LSB- Zernik88 -RSB- , to facilitate language acquisition .", "label": "Hypohym Of", "id": "train_3_73"}
{"text": "We demonstrate that an approximation of HPSG produces a more effective [[ CFG filter ]] than << that >> of LTAG .", "label": "Compare", "id": "train_3_74"}
{"text": "This << system >> consists of one or more reference times and temporal perspective times , the speech time and the [[ location time ]] .", "label": "Part Of", "id": "train_3_75"}
{"text": "This paper presents a method for << blind estimation of reverberation times >> in [[ reverberant enclosures ]] .", "label": "Feature Of", "id": "train_3_76"}
{"text": "Previous approaches learned models based just on [[ positions ]] and << velocities >> of the body parts while ignoring their appearance .", "label": "Conjunction", "id": "train_3_77"}
{"text": "We have recently shown that the fusion of measurement information with system dynamics and shape priors greatly improves the tracking performance for very << noisy images >> such as [[ ultrasound sequences ]] -LSB- 22 -RSB- .", "label": "Hypohym Of", "id": "train_3_78"}
{"text": "The use of BLEU at the character level eliminates the word segmentation problem : [[ it ]] makes it possible to directly compare commercial systems outputting unsegmented texts with , for instance , << statistical MT systems >> which usually segment their outputs .", "label": "Evaluate For", "id": "train_3_79"}
{"text": "Our [[ algorithms ]] outperform << baseline seg-mentation algorithms >> .", "label": "Compare", "id": "train_3_80"}
{"text": "In the phase of training , a basic << visual vocabulary >> consisting of [[ blob-tokens ]] to describe the image content is generated at first ; then the statistical relationship is modeled between the blob-tokens and keywords by a Maximum Entropy Model constructed from the training set of labeled images .", "label": "Part Of", "id": "train_3_81"}
{"text": "A support vector machine uses these [[ features ]] to capture << breakdowns in coherence >> due to relatedness to the essay question and relatedness between discourse elements .", "label": "Used For", "id": "train_3_82"}
{"text": "This study compares the effect of [[ noise ]] and reverberation on << depression prediction >> using 1 -RRB- standard mel-frequency cepstral coefficients -LRB- MFCCs -RRB- , and 2 -RRB- features designed for noise robustness , damped oscillator cepstral coefficients -LRB- DOCCs -RRB- .", "label": "Feature Of", "id": "train_3_83"}
{"text": "The paper also describes new [[ parameter determination ]] and << quantisation techniques >> vital to the operation of this coder at such low bit rates .", "label": "Conjunction", "id": "train_3_84"}
{"text": "On this basis , we discuss the problems of vagueness and [[ ambiguity ]] in << semantic annotation >> .", "label": "Feature Of", "id": "train_3_85"}
{"text": "This is the significant advantage of the << fluorescence-based method >> over previous [[ methods ]] based on reflection .", "label": "Compare", "id": "train_3_86"}
{"text": "Our << method >> achieves new state-of-the-art results on the [[ Flickr30K and MSCOCO image-sentence datasets ]] and shows promise on the new task of phrase lo-calization on the Flickr30K Entities dataset .", "label": "Evaluate For", "id": "train_3_87"}
{"text": "The information gained from corpus research and the analyses that are proposed are realized in the framework of [[ SILVA ]] , a << parsing and extraction tool >> for German text corpora .", "label": "Hypohym Of", "id": "train_3_88"}
{"text": "The objective of this project is to develop a << robust and high-performance speech recognition system >> using a [[ segment-based approach ]] to phonetic recognition .", "label": "Used For", "id": "train_3_89"}
{"text": "[[ Dictionary construction ]] , one of the most difficult tasks in developing a << machine translation system >> , is expensive .", "label": "Part Of", "id": "train_3_90"}
{"text": "We present examples which suggest that in a << pipelined NLG architecture >> , the best approach is to strongly tie it to a [[ revision component ]] .", "label": "Part Of", "id": "train_3_91"}
{"text": "The estimation is then used to select the best acoustic model out of a library of << models >> trained in various [[ artificial re-verberant conditions ]] .", "label": "Feature Of", "id": "train_3_92"}
{"text": "Experiments show that this [[ approach ]] is superior to a single << decision-tree classifier >> .", "label": "Compare", "id": "train_3_93"}
{"text": "We also discuss exploitation of the [[ database ]] for working out a more adequate tagging and << lemmatization >> .", "label": "Used For", "id": "train_3_94"}
{"text": "We attack an inexplicably << under-explored language genre of spoken language >> -- [[ lyrics in music ]] -- via completely unsuper-vised induction of an SMT-style stochastic transduction grammar for hip hop lyrics , yielding a fully-automatically learned challenge-response system that produces rhyming lyrics given an input .", "label": "Hypohym Of", "id": "train_3_95"}
{"text": "Evaluation of our << system >> on MUC-6 and MUC-7 English NE tasks achieves [[ F-measures ]] of 96.6 % and 94.1 % respectively .", "label": "Evaluate For", "id": "train_3_96"}
{"text": "We explore a variety of predictive models , including [[ Na \u00a8 \u0131ve Bayes mixture models ]] and << mixtures of Markov models >> , and report empirical evidence that MINPATH finds useful shortcuts that save substantial navigational effort .", "label": "Conjunction", "id": "train_3_97"}
{"text": "The class of languages generated is shown to lie strictly between the [[ context-free languages ]] and the << indexed languages >> .", "label": "Conjunction", "id": "train_3_98"}
{"text": "The analysis in -LRB- Partee , 1984 -RRB- of quantified sentences , introduced by a temporal connective , gives the wrong truth-conditions when the [[ temporal connective ]] in the << subordinate clause >> is before or after .", "label": "Part Of", "id": "train_3_99"}
{"text": "Performance of the [[ algorithm ]] is contrasted with << human annotation >> performance .", "label": "Compare", "id": "train_3_100"}
{"text": "In this paper , for the first time , we propose to use a [[ Neural Network classifier ]] furnished by an SAE structure for detecting the errors made by a strong << Automatic Speech Recognition -LRB- ASR -RRB- system >> .", "label": "Used For", "id": "train_3_101"}
{"text": "The representation contains complementary information to that learned from << supervised image datasets >> like [[ ImageNet ]] .", "label": "Hypohym Of", "id": "train_3_102"}
{"text": "The experimental results demonstrated that the annotation performance of this method outperforms some traditional << annotation methods >> by about 8 % in [[ mean precision ]] , showing a potential of the Maximum Entropy Model in the task of automatic image annotation .", "label": "Evaluate For", "id": "train_3_103"}
{"text": "Our << measure >> can be exactly calculated in [[ quadratic time ]] .", "label": "Feature Of", "id": "train_3_104"}
{"text": "We describe a new method for the representation of << NLP structures >> within [[ reranking approaches ]] .", "label": "Feature Of", "id": "train_3_105"}
{"text": "This paper presents an approach to estimate the << intrinsic texture properties -LRB- albedo , shading , normal -RRB- of scenes >> from [[ multiple view acquisition ]] under unknown illumination conditions .", "label": "Used For", "id": "train_3_106"}
{"text": "Experiments on the [[ LabelMe data set ]] showed that the proposed models significantly out-perform a << baseline global feature-based approach >> .", "label": "Evaluate For", "id": "train_3_107"}
{"text": "By extensive experiments , we show that our [[ learned representation ]] can significantly boost several video recognition tasks -LRB- retrieval , classification , and highlight detection -RRB- over traditional << video representations >> .", "label": "Compare", "id": "train_3_108"}
{"text": "Some of the << principles >> which are relevant to the topic of this paper are : -LRB- a -RRB- Multiple Layer of Grammars -LRB- b -RRB- [[ Multiple Layer Presentation ]] -LRB- c -RRB- Lexicon Driven Processing -LRB- d -RRB- Form-Oriented Dictionary Description .", "label": "Part Of", "id": "train_3_109"}
{"text": "Next , we provide baseline results on the animated GIF description task , using three representative techniques : [[ nearest neighbor ]] , << statistical machine translation >> , and recurrent neural networks .", "label": "Conjunction", "id": "train_3_110"}
{"text": "A method of sense resolution is proposed that is based on WordNet , an on-line lexical database that incorporates << semantic relations >> -LRB- synonymy , antonymy , [[ hyponymy ]] , meronymy , causal and troponymic entailment -RRB- as labeled pointers between word senses .", "label": "Hypohym Of", "id": "train_3_111"}
{"text": "Furthermore , we present a standalone system that resolves [[ pronouns ]] in << unannotated text >> by using a fully automatic sequence of preprocessing modules that mimics the manual annotation process .", "label": "Part Of", "id": "train_3_112"}
{"text": "Because of its adaptive nature , Bayesian learning serves as a unified approach for the following four speech recognition applications , namely parameter smoothing , [[ speaker adaptation ]] , << speaker group modeling >> and corrective training .", "label": "Conjunction", "id": "train_3_113"}
{"text": "We develop several blur features modeled by image color , gradient , and spectrum information , and use [[ feature parameter training ]] to robustly classify << blurred images >> .", "label": "Used For", "id": "train_3_114"}
{"text": "We evaluate our approach on several standard << datasets >> such as [[ im2gps ]] , San Francisco and MediaEval2010 , and obtain state-of-the-art results .", "label": "Hypohym Of", "id": "train_3_115"}
{"text": "Thus the work reported addresses two [[ robustness problems ]] faced by current experimental << natural language processing systems >> : coping with an incomplete lexicon and with incomplete knowledge of phrasal constructions .", "label": "Feature Of", "id": "train_3_116"}
{"text": "We also report results of a preliminary , [[ qualitative user evaluation ]] of the << system >> , which while broadly positive indicates further work needs to be done on the interface to make users aware of the increased potential of IE-enhanced text browsers .", "label": "Evaluate For", "id": "train_3_117"}
{"text": "In experiments using the Penn WSJ corpus , our automatically trained [[ model ]] gave a performance of 86.6 % -LRB- F1 , sentences < 40 words -RRB- , which is comparable to that of an << unlexicalized PCFG parser >> created using extensive manual feature selection .", "label": "Compare", "id": "train_3_118"}
{"text": "This model is an extension of << PCFG >> in which [[ non-terminal symbols ]] are augmented with latent variables .", "label": "Part Of", "id": "train_3_119"}
{"text": "Extensive experiments in common << applications >> such as [[ 2D/3D image segmentations ]] and 3D surface fitting demonstrate the effectiveness of our approach .", "label": "Hypohym Of", "id": "train_3_120"}
{"text": "We compare two wide-coverage lexicalized grammars of English , [[ LEXSYS ]] and << XTAG >> , finding that the two grammars exploit EDOL in different ways .", "label": "Compare", "id": "train_3_121"}
{"text": "In real-world action recognition problems , low-level features can not adequately characterize the [[ rich spatial-temporal structures ]] in << action videos >> .", "label": "Feature Of", "id": "train_3_122"}
{"text": "The system participated in all the tracks of the segmentation bakeoff -- PK-open , [[ PK-closed ]] , << AS-open >> , AS-closed , HK-open , HK-closed , MSR-open and MSR - closed -- and achieved the state-of-the-art performance in MSR-open , MSR-close and PK-open tracks .", "label": "Conjunction", "id": "train_3_123"}
{"text": "We show that there is unambiguous association between visual content and natural language descriptions in our dataset , making [[ it ]] an ideal benchmark for the << visual content captioning task >> .", "label": "Evaluate For", "id": "train_3_124"}
{"text": "The proposed << algorithm >> is based on a [[ statistical model of short-term log-energy sequences ]] for echo-free speech .", "label": "Used For", "id": "train_3_125"}
{"text": "In particular , it describes a robust explanation system that constructs multisentential and multi-paragraph explanations from the a << large-scale knowledge base >> in the domain of botanical anatomy , physiology , and [[ development ]] .", "label": "Feature Of", "id": "train_3_126"}
{"text": "This paper proposes an automatic , essentially << domain-independent means of evaluating Spoken Language Systems -LRB- SLS -RRB- >> which combines [[ software ]] we have developed for that purpose -LRB- the '' Comparator '' -RRB- and a set of specifications for answer expressions -LRB- the '' Common Answer Specification '' , or CAS -RRB- .", "label": "Part Of", "id": "train_3_127"}
{"text": "In spite of the level of difficulty of the challenge , the [[ model ]] nevertheless produces fluent output as judged by human evaluators , and performs significantly better than widely used << phrase-based SMT models >> upon the same task .", "label": "Compare", "id": "train_3_128"}
{"text": "Finally , we evaluate the << approach >> in a working [[ multi-page system ]] .", "label": "Evaluate For", "id": "train_3_129"}
{"text": "Later , however , Breiman cast serious doubt on this explanation by introducing a << boosting algorithm >> , [[ arc-gv ]] , that can generate a higher margins distribution than AdaBoost and yet performs worse .", "label": "Hypohym Of", "id": "train_3_130"}
{"text": "Experiments were done for two ag-glutinative and morphologically rich languages : [[ Finnish ]] and << Turk-ish >> .", "label": "Conjunction", "id": "train_3_131"}
{"text": "The main feature of this model is to view parsing and generation as two strongly interleaved << tasks >> performed by a single [[ parametrized deduction process ]] .", "label": "Used For", "id": "train_3_132"}
{"text": "[[ It ]] also gets a precision of 70 % and a recall of 49 % in the task of << placing commas >> .", "label": "Used For", "id": "train_3_133"}
{"text": "These theoretical results show that one can intrinsically segment a << piece-wise planar scene >> from [[ 2-D images ]] without explicitly performing any 3-D reconstruction .", "label": "Feature Of", "id": "train_3_134"}
{"text": "The results of the experiments demonstrate that the [[ HDAG Kernel ]] is superior to other kernel functions and << baseline methods >> .", "label": "Compare", "id": "train_3_135"}
{"text": "This paper solves the automatic initial-ization problem by performing boosted shape detection as a generic measurement process and integrating [[ it ]] in our << tracking framework >> .", "label": "Part Of", "id": "train_3_136"}
{"text": "Additionally , a novel and likewise [[ automatic and unsupervised evaluation method ]] inspired by Schutze 's -LRB- 1992 -RRB- idea of evaluation of << word sense disambiguation algorithms >> is employed .", "label": "Evaluate For", "id": "train_3_137"}
{"text": "Furthermore , the << maximum margin criterion >> , e.g. , intra-class com-pactness and [[ inter-class penalty ]] , on the output layer is imposed to seek more discriminative features across different domains .", "label": "Hypohym Of", "id": "train_3_138"}
{"text": "Ideally , these are basic vocabulary units suitable for different tasks , such as speech and text understanding , [[ machine translation ]] , << information retrieval >> , and statistical language modeling .", "label": "Conjunction", "id": "train_3_139"}
