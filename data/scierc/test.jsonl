{"text": "This << system >> achieves an error reduction of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for [[ gold-standard parse trees ]] on PropBank .", "label": "Evaluate For", "id": "test_0"}
{"text": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use [[ lexical affinity ]] to create << sequential models >> , in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus .", "label": "Used For", "id": "test_1"}
{"text": "The nonlinear scale space is built using efficient [[ Additive Operator Splitting -LRB- AOS -RRB- techniques ]] and << variable con-ductance diffusion >> .", "label": "Conjunction", "id": "test_2"}
{"text": "We establish sufficient conditions for the [[ concavity ]] of our << reweighted objective function >> in terms of weight assignments in the Kikuchi expansion , and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges .", "label": "Feature Of", "id": "test_3"}
{"text": "We evaluate our << approach >> against the [[ state-of-the-art techniques ]] and show that our work improves both the quality and the efficiency of entity summarization .", "label": "Compare", "id": "test_4"}
{"text": "-LRB- ii -RRB- High quality << translation >> via word sense disambiguation and accurate [[ word order generation ]] of the target language .", "label": "Used For", "id": "test_5"}
{"text": "The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation modules mediated by a << language neutral meaning representation >> called a [[ semantic frame ]] .", "label": "Hypohym Of", "id": "test_6"}
{"text": "This system can be a very useful [[ tool ]] for << linguistic knowledge discovery >> and other NLP tasks .", "label": "Used For", "id": "test_7"}
{"text": "Based on a corpus annotation project , this paper reports the discursive usage of 6 [[ Chinese punctuation marks ]] in << news commentary texts >> : Colon , Dash , Ellipsis , Exclamation Mark , Question Mark , and Semicolon .", "label": "Part Of", "id": "test_8"}
{"text": "<< Global registration >> is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a [[ bundle adjustment ]] which uses only the homographies computed in the previous steps .", "label": "Used For", "id": "test_9"}
{"text": "The CCLINC Korean-to-English translation system consists of two core modules , << language understanding and generation modules >> mediated by a [[ language neutral meaning representation ]] called a semantic frame .", "label": "Used For", "id": "test_10"}
{"text": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use models of verbal interaction ; as a device combining knowledge about [[ dialog schemata ]] and about << verbal interaction >> with knowledge about task-oriented and goal-directed dialogs .", "label": "Conjunction", "id": "test_11"}
{"text": "The [[ rhetorical patterns ]] of these << marks >> are compared against patterns around cue phrases in general .", "label": "Feature Of", "id": "test_12"}
{"text": "[[ Dividing sentences in chunks of words ]] is a useful preprocessing step for << parsing >> , information extraction and information retrieval .", "label": "Used For", "id": "test_13"}
{"text": "The [[ system ]] was then transferred from the << RM task >> to the ATIS CSR task and a limited number of development tests performed .", "label": "Used For", "id": "test_14"}
{"text": "Experimental results on two challenging [[ datasets ]] , MSRII and UCF 101 , validate the superior performance of our << action proposals >> as well as competitive results on action detection and search .", "label": "Evaluate For", "id": "test_15"}
{"text": "Experimental results on two challenging << datasets >> , MSRII and [[ UCF 101 ]] , validate the superior performance of our action proposals as well as competitive results on action detection and search .", "label": "Hypohym Of", "id": "test_16"}
{"text": "We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different << shapes >> -LRB- i.e. , [[ sizes ]] and orientations -RRB- can be produced by locating the local maximum likelihoods .", "label": "Hypohym Of", "id": "test_17"}
{"text": "By relaxing the mesh connectivity requirement , we extend [[ ROD-TV ]] and propose a simple but effective << multiscale feature extraction algorithm >> .", "label": "Used For", "id": "test_18"}
{"text": "Results show that these [[ Chinese punctuation marks ]] , though fewer in number than << cue phrases >> , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclearity in Chinese texts .", "label": "Compare", "id": "test_19"}
{"text": "In comparison with previous models , which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we focus on [[ models ]] intended to capture the << co-occurrence patterns >> of any pair of words or phrases at any distance in the corpus .", "label": "Used For", "id": "test_20"}
{"text": "Information extraction techniques automatically create structured databases from unstructured data sources , such as the [[ Web ]] or << newswire documents >> .", "label": "Conjunction", "id": "test_21"}
{"text": "To overcome the [[ singularity problem ]] of the << least squares estimate -LRB- LSE -RRB- method >> , an approximate least squares estimate -LRB- ALSE -RRB- method is proposed to estimate the parameters of the ACGMRF model .", "label": "Feature Of", "id": "test_22"}
{"text": "We present the first application of the [[ head-driven statistical parsing model ]] of Collins -LRB- 1999 -RRB- as a simultaneous language model and << parser >> for large-vocabulary speech recognition .", "label": "Used For", "id": "test_23"}
{"text": "This methodology allows reducing the [[ time complexity ]] of the << algorithm >> while classification results remain high .", "label": "Evaluate For", "id": "test_24"}
{"text": "The results show the [[ Dau ]] and the << glimpse measures >> to be the best predictors of intelligibility , with correlations of around 0.83 to subjective scores .", "label": "Conjunction", "id": "test_25"}
{"text": "For the << generation of synthesized speech >> we used a state of the art [[ HMM-based speech synthesis system ]] .", "label": "Used For", "id": "test_26"}
{"text": "In experiments , we solved 50 noun WSD problems in the [[ Japanese Dictionary Task ]] in << SENSEVAL2 >> .", "label": "Feature Of", "id": "test_27"}
{"text": "This paper presents an [[ algorithm ]] for << computing optical flow , shape , motion , lighting , and albedo >> from an image sequence of a rigidly-moving Lambertian object under distant illumination .", "label": "Used For", "id": "test_28"}
{"text": "Our empirical results , which hold for all examined language pairs , suggest that the highest levels of performance can be obtained through relatively simple << means >> : [[ heuristic learning of phrase translations ]] from word-based alignments and lexical weighting of phrase translations .", "label": "Hypohym Of", "id": "test_29"}
{"text": "We evaluate the system on twenty Switchboard dialogues and show that [[ it ]] compares well to << Byron 's -LRB- 2002 -RRB- manually tuned system >> .", "label": "Compare", "id": "test_30"}
{"text": "[[ Locally inferred surface elements ]] are robust to noise and better capture << local shapes >> .", "label": "Used For", "id": "test_31"}
{"text": "In this paper , we propose a new approach to generate << oriented object proposals -LRB- OOPs -RRB- >> to reduce the [[ detection error ]] caused by various orientations of the object .", "label": "Evaluate For", "id": "test_32"}
{"text": "In contrast to other works that address this problem using multiple classifiers , each one specialized for a specific orientation , we propose a simple two-step << approach >> with an estimation stage and a [[ classification stage ]] .", "label": "Part Of", "id": "test_33"}
{"text": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our << results >> reveal a step forward in performance both in detection and [[ description ]] against previous state-of-the-art methods .", "label": "Evaluate For", "id": "test_34"}
{"text": "We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the [[ efficiency ]] of << entity summarization >> .", "label": "Evaluate For", "id": "test_35"}
{"text": "To incorporate the << trigger words >> whose effectiveness have been experimentally evaluated in several previous works , we propose a novel [[ architecture ]] with an attention mechanism .", "label": "Used For", "id": "test_36"}
{"text": "We evaluated three intel-ligibility measures , the Dau measure , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a << quality measure >> , the [[ Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- ]] .", "label": "Hypohym Of", "id": "test_37"}
{"text": "Experiments on the Wall Street Journal treebank and lattice corpora show [[ word error rates ]] competitive with the standard << n-gram language model >> while extracting additional structural information useful for speech understanding .", "label": "Evaluate For", "id": "test_38"}
{"text": "This << method >> requires a source-language dependency parser , [[ target language word segmentation ]] and an unsupervised word alignment component .", "label": "Used For", "id": "test_39"}
{"text": "Our contributions include a [[ concise , modular architecture ]] with reversible processes of understanding and << generation >> , an information-state model of reference , and flexible links between semantics and collaborative problem solving .", "label": "Used For", "id": "test_40"}
{"text": "The method exploits [[ on-line encyclopedias and dictionaries ]] to generate automatically an arbitrarily large number of << positive and negative definition examples >> , which are then used to train an svm to separate the two classes .", "label": "Used For", "id": "test_41"}
{"text": "Specifically , we highlight the importance of diversified -LRB- faceted -RRB- summaries by combining three dimensions : diversity , [[ uniqueness ]] , and << popularity >> .", "label": "Conjunction", "id": "test_42"}
{"text": "The << nonlinear scale space >> is built using efficient Additive Operator Splitting -LRB- AOS -RRB- techniques and [[ variable con-ductance diffusion ]] .", "label": "Used For", "id": "test_43"}
{"text": "<< ROD-TV >> simultaneously delivers good efficiency and [[ robust-ness ]] , by adapting to a continuum of primitive connectivity , view dependence , and levels of detail -LRB- LOD -RRB- .", "label": "Evaluate For", "id": "test_44"}
{"text": "In this work , we present a [[ technique ]] for << robust estimation >> , which by explicitly incorporating the inherent uncertainty of the estimation procedure , results in a more efficient robust estimation algorithm .", "label": "Used For", "id": "test_45"}
{"text": "Next , the benefits and costs of implementing a [[ user modeling component ]] for a << system >> are weighed in light of several aspects of the interaction requirements that may be imposed by the system .", "label": "Part Of", "id": "test_46"}
{"text": "Second , we devise a new track clustering cost function that includes << occlusion reasoning >> , in the form of [[ depth ordering constraints ]] , as well as motion similarity along the tracks .", "label": "Feature Of", "id": "test_47"}
{"text": "The development of such a model appears to be important in several respects : as a device to represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to represent and to use [[ models ]] of << verbal interaction >> ; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs .", "label": "Used For", "id": "test_48"}
{"text": "Representative samples from an entity-oriented language definition are presented , along with a control structure for an entity-oriented parser , some << parsing strategies >> that use the [[ control structure ]] , and worked examples of parses .", "label": "Used For", "id": "test_49"}
{"text": "Experimental results on two challenging datasets , MSRII and UCF 101 , validate the superior performance of our << action proposals >> as well as competitive results on [[ action detection and search ]] .", "label": "Evaluate For", "id": "test_50"}
{"text": "<< It >> is applied on demand to the visible subset of data at a desired level of detail , by traversing the data hierarchy and [[ collecting tensorial support ]] in a neighborhood .", "label": "Used For", "id": "test_51"}
{"text": "Both the use of [[ supervised learning ]] and working on the gradient space makes our << approach >> robust while being efficient at run-time .", "label": "Used For", "id": "test_52"}
{"text": "We then develop a << deep triplet-ranking model >> for instance-level SBIR with a novel data augmentation and [[ staged pre-training strategy ]] to alleviate the issue of insufficient fine-grained training data .", "label": "Used For", "id": "test_53"}
{"text": "We show experimentally that the proposed method is viable , that [[ it ]] outperforms the << alternative >> of training the system on questions and news articles from trec , and that it helps the search engine handle definition questions significantly better .", "label": "Compare", "id": "test_54"}
{"text": "We evaluate our [[ approach ]] against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of << entity summarization >> .", "label": "Used For", "id": "test_55"}
{"text": "We evaluated three intel-ligibility measures , the Dau measure , the [[ glimpse proportion ]] and the << Speech Intelligibility Index -LRB- SII -RRB- >> and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .", "label": "Conjunction", "id": "test_56"}
{"text": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a probabilistic model which has performed well on information extraction tasks because of its ability to capture [[ arbitrary , overlapping features ]] of the input in a << Markov model >> .", "label": "Part Of", "id": "test_57"}
{"text": "Experiments on the Wall Street Journal treebank and [[ lattice corpora ]] show word error rates competitive with the standard << n-gram language model >> while extracting additional structural information useful for speech understanding .", "label": "Evaluate For", "id": "test_58"}
{"text": "By incorporating trigger words into the consideration , the relative improvement of the proposed method over the << state-of-the-art method >> is around 9.4 % in the [[ F1-score ]] .", "label": "Evaluate For", "id": "test_59"}
{"text": "Experimental comparison with other << techniques >> shows the effectiveness of our [[ approach ]] .", "label": "Compare", "id": "test_60"}
{"text": "In this paper , we will describe a [[ search tool ]] for a huge set of << ngrams >> .", "label": "Used For", "id": "test_61"}
{"text": "Special attention is given to the part of the parser that checks the fulfillment of [[ logical well-formedness conditions ]] on << trees >> .", "label": "Feature Of", "id": "test_62"}
{"text": "Our results show that [[ multi-view constraints ]] can significantly improve << estimates of both scene illuminants and object color -LRB- surface reflectance -RRB- >> when compared to a baseline single-view method .", "label": "Used For", "id": "test_63"}
{"text": "This paper presents an algorithm for computing optical flow , shape , motion , lighting , and albedo from an << image sequence >> of a [[ rigidly-moving Lambertian object ]] under distant illumination .", "label": "Feature Of", "id": "test_64"}
{"text": "This paper presents a new << interactive disambiguation scheme >> based on the [[ paraphrasing ]] of a parser 's multiple output .", "label": "Used For", "id": "test_65"}
{"text": "We aim to capture such interactions and to construct a powerful [[ intermediate-level video representation ]] for subsequent << recognition >> .", "label": "Used For", "id": "test_66"}
{"text": "ROD-TV simultaneously delivers good efficiency and robust-ness , by adapting to a continuum of << primitive connectivity >> , [[ view dependence ]] , and levels of detail -LRB- LOD -RRB- .", "label": "Conjunction", "id": "test_67"}
{"text": "In the case of known expert competence levels , we give [[ sharp error estimates ]] for the << optimal rule >> .", "label": "Used For", "id": "test_68"}
{"text": "Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art << proposal generation methods >> in either [[ object rotation scenarios ]] or general scenarios .", "label": "Evaluate For", "id": "test_69"}
{"text": "The << nonlinear scale space >> is built using efficient [[ Additive Operator Splitting -LRB- AOS -RRB- techniques ]] and variable con-ductance diffusion .", "label": "Used For", "id": "test_70"}
{"text": "We evaluated three << intel-ligibility measures >> , the [[ Dau measure ]] , the glimpse proportion and the Speech Intelligibility Index -LRB- SII -RRB- and a quality measure , the Perceptual Evaluation of Speech Quality -LRB- PESQ -RRB- .", "label": "Hypohym Of", "id": "test_71"}
{"text": "Further experiments show that the rotation invariant property helps a [[ class-specific object detector ]] achieve better performance than the state-of-the-art << proposal generation methods >> in either object rotation scenarios or general scenarios .", "label": "Compare", "id": "test_72"}
{"text": "We focus on FAQ-like questions and answers , and build our system around a [[ noisy-channel architecture ]] which exploits both a << language model >> for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .", "label": "Used For", "id": "test_73"}
{"text": "The [[ model ]] is adapted to an << online left to right chart-parser >> for word lattices , integrating acoustic , n-gram , and parser probabilities .", "label": "Used For", "id": "test_74"}
{"text": "In order to deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar -LRB- PCFG -RRB- , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a [[ probability-based scoring function ]] which determines the likelihood of each successful << parse >> .", "label": "Used For", "id": "test_75"}
{"text": "The << classifier >> we use in both stages is based on a [[ boosted combination of Random Ferns ]] over local histograms of oriented gradients -LRB- HOGs -RRB- , which we compute during a pre-processing step .", "label": "Used For", "id": "test_76"}
{"text": "The [[ method ]] exploits << on-line encyclopedias and dictionaries >> to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used to train an svm to separate the two classes .", "label": "Used For", "id": "test_77"}
{"text": "We then develop a [[ deep triplet-ranking model ]] for << instance-level SBIR >> with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data .", "label": "Used For", "id": "test_78"}
{"text": "Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space , but comparable to SIFT , our results reveal a step forward in performance both in [[ detection ]] and << description >> against previous state-of-the-art methods .", "label": "Conjunction", "id": "test_79"}
{"text": "All measures gave less accurate predictions of intelligibility for [[ synthetic speech ]] than have previously been found for << natural speech >> ; in particular the SII measure .", "label": "Compare", "id": "test_80"}
{"text": "This paper explores the role of [[ user modeling ]] in such << systems >> .", "label": "Part Of", "id": "test_81"}
{"text": "Each action proposal corresponds to a temporal series of spatial bounding boxes , i.e. , a [[ spatio-temporal video tube ]] , which has a good potential to locate one << human action >> .", "label": "Used For", "id": "test_82"}
{"text": "This << system >> achieves an [[ error reduction ]] of 22 % on all arguments and 32 % on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank .", "label": "Evaluate For", "id": "test_83"}
{"text": "In order to deal with ambiguity , the << MORphological PArser MORPA >> is provided with a [[ probabilistic context-free grammar -LRB- PCFG -RRB- ]] , i.e. it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse .", "label": "Used For", "id": "test_84"}
{"text": "Dividing sentences in chunks of words is a useful preprocessing step for [[ parsing ]] , << information extraction >> and information retrieval .", "label": "Conjunction", "id": "test_85"}
{"text": "We formulate the proposal generation problem as a generative proba-bilistic model such that << object proposals >> of different shapes -LRB- i.e. , sizes and orientations -RRB- can be produced by locating the [[ local maximum likelihoods ]] .", "label": "Used For", "id": "test_86"}
{"text": "Having been trained on [[ Korean newspaper articles ]] on missiles and chemical biological warfare , the << system >> produces the translation output sufficient for content understanding of the original document .", "label": "Used For", "id": "test_87"}
{"text": "This paper develops an anisotropic circular Gaussian MRF -LRB- ACGMRF -RRB- model for [[ modelling rotated image textures ]] and << retrieving rotation-invariant texture features >> .", "label": "Conjunction", "id": "test_88"}
{"text": "To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works , we propose a novel << architecture >> with an [[ attention mechanism ]] .", "label": "Feature Of", "id": "test_89"}
{"text": "The information extraction system we evaluate is based on a linear-chain conditional random field -LRB- CRF -RRB- , a [[ probabilistic model ]] which has performed well on information extraction tasks because of its ability to capture << arbitrary , overlapping features >> of the input in a Markov model .", "label": "Used For", "id": "test_90"}
{"text": "Specifically , we highlight the importance of << diversified -LRB- faceted -RRB- summaries >> by combining three dimensions : [[ diversity ]] , uniqueness , and popularity .", "label": "Feature Of", "id": "test_91"}
{"text": "It is applied on demand to the visible subset of data at a desired level of detail , by [[ traversing the data hierarchy ]] and << collecting tensorial support >> in a neighborhood .", "label": "Conjunction", "id": "test_92"}
{"text": "The results show the Dau and the << glimpse measures >> to be the best predictors of intelligibility , with [[ correlations ]] of around 0.83 to subjective scores .", "label": "Evaluate For", "id": "test_93"}
{"text": "After picking those spatiotem-poral paths of high actionness scores , our action proposal generation is formulated as a maximum set coverage problem , where [[ greedy search ]] is performed to select a set of << action proposals >> that can maximize the overall actionness score .", "label": "Used For", "id": "test_94"}
{"text": "In this paper , we improve an unsupervised learning method using the Expectation-Maximization -LRB- EM -RRB- algorithm proposed by Nigam et al. for text classification problems in order to apply [[ it ]] to << word sense disambiguation -LRB- WSD -RRB- problems >> .", "label": "Used For", "id": "test_95"}
{"text": "We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the [[ linguistic generality ]] available in a << parser >> .", "label": "Feature Of", "id": "test_96"}
{"text": "The << noisy conditions >> comprised four [[ additive noises ]] .", "label": "Part Of", "id": "test_97"}
{"text": "[[ MORPA ]] is a fully implemented << parser >> developed for use in a text-to-speech conversion system .", "label": "Hypohym Of", "id": "test_98"}
{"text": "Experiments on the [[ Wall Street Journal treebank ]] and << lattice corpora >> show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding .", "label": "Conjunction", "id": "test_99"}
