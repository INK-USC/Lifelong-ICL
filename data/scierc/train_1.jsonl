{"text": "The results show the performance of the proposed << approach >> on [[ simulated data ]] .", "label": "Evaluate For", "id": "train_1_0"}
{"text": "This paper investigates critical configurations for << projective reconstruction >> from multiple [[ images ]] taken by a camera moving in a straight line .", "label": "Used For", "id": "train_1_1"}
{"text": "For this purpose , a file card model of discourse model and knowledge store is introduced enabling the decomposition and formal representation of its determination process as a << programmable algorithm >> -LRB- [[ FDA ]] -RRB- .", "label": "Hypohym Of", "id": "train_1_2"}
{"text": "This new [[ algorithm ]] deviates from the traditional << approach of wall building and layering >> .", "label": "Compare", "id": "train_1_3"}
{"text": "I show that the performance of a << search engine >> can be improved dramatically by incorporating an [[ approximation of the formal analysis ]] that is compatible with the search engine 's operational semantics .", "label": "Part Of", "id": "train_1_4"}
{"text": "Performance of each investigated classifier is evaluated both via [[ receiving operating curve ]] and via a << measure >> , called mean absolute error , related to the quality in predicting the corresponding word error rate .", "label": "Conjunction", "id": "train_1_5"}
{"text": "We are the first to bring the closed form solution to such a very practical << problem >> arising in [[ video surveillance ]] .", "label": "Feature Of", "id": "train_1_6"}
{"text": "Inference in these models involves solving a combinatorial optimization problem , with << methods >> such as graph cuts , [[ belief propagation ]] .", "label": "Used For", "id": "train_1_7"}
{"text": "The agreement in question involves number in nouns and reflexive pronouns and is syntactic rather than semantic in nature because grammatical number in English , like [[ grammatical gender ]] in << languages >> such as French , is partly arbitrary .", "label": "Feature Of", "id": "train_1_8"}
{"text": "First , beyond the aging dictionaries , each subject may have extra << personalized facial characteristics >> , e.g. [[ mole ]] , which are invariant in the aging process .", "label": "Hypohym Of", "id": "train_1_9"}
{"text": "It was compiled from various resources such as encyclopedias and dictionaries , public databases of proper names and toponyms , << collocations >> obtained from Czech WordNet , [[ lists of botanical and zoological terms ]] and others .", "label": "Conjunction", "id": "train_1_10"}
{"text": "These applications require high [[ accuracy ]] for the << estimation of the motion field >> since the most interesting parameters of the dynamical processes studied are contained in first-order derivatives of the motion field or in dynamical changes of the moving objects .", "label": "Evaluate For", "id": "train_1_11"}
{"text": "Interdisciplinary evidence from social and cognitive psychology is cited and the prospect of the integration of focus via FDA as a [[ discourse-level construct ]] into << speech synthesis systems >> , in particular , concept-to-speech systems , is also briefly discussed .", "label": "Part Of", "id": "train_1_12"}
{"text": "An empirical comparison of CFG filtering techniques for [[ LTAG ]] and << HPSG >> is presented .", "label": "Compare", "id": "train_1_13"}
{"text": "Motivated by these arguments , we introduce a number of new << performance enhancing techniques >> including part of speech tagging , new [[ similarity measures ]] and expanded stop lists .", "label": "Part Of", "id": "train_1_14"}
{"text": "On a subset of the most difficult SENSEVAL-2 nouns , the accuracy difference between the two approaches is only 14.0 % , and the difference could narrow further to 6.5 % if we disregard the advantage that << manually sense-tagged data >> have in their [[ sense coverage ]] .", "label": "Feature Of", "id": "train_1_15"}
{"text": "Contrary to existing [[ greedy techniques ]] , these << tasks >> are posed in the form of a discrete global optimization problem with a well defined objective function .", "label": "Compare", "id": "train_1_16"}
{"text": "Through two experiments , three methods for constructing word vectors , i.e. , LSA-based , cooccurrence-based and dictionary-based methods , were compared in terms of the ability to represent two kinds of << similarity >> , i.e. , taxonomic similarity and [[ associative similarity ]] .", "label": "Hypohym Of", "id": "train_1_17"}
{"text": "In this paper , we introduce a closed-form solution to systematically combine the [[ limited training data ]] with some generic << qualitative knowledge >> for BN parameter learning .", "label": "Conjunction", "id": "train_1_18"}
{"text": "In this paper , we propose a more principled [[ way ]] to identify << annotation outliers >> by formulating the interestingness prediction task as a unified robust learning to rank problem , tackling both the outlier detection and interestingness prediction tasks jointly .", "label": "Used For", "id": "train_1_19"}
{"text": "In this paper , we propose an [[ automatic estimation method ]] for << word significance -LRB- weights -RRB- >> based on its influence on IR .", "label": "Evaluate For", "id": "train_1_20"}
{"text": "This paper proposes a method for learning joint embed-dings of images and text using a two-branch neural network with [[ multiple layers of linear projections ]] followed by << nonlinearities >> .", "label": "Conjunction", "id": "train_1_21"}
{"text": "We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments , and contrast the quality with [[ paraphrases ]] extracted from << automatic alignments >> .", "label": "Part Of", "id": "train_1_22"}
{"text": "Through experiments with parallel corpora of a Korean and English language pairs , we show that our << paraphrasing method >> effectively extracts paraphrases with high [[ precision ]] , 94.3 % and 84.6 % respectively for Korean and English , and the translation knowledge extracted from the bilingual corpora could be generalized successfully using the paraphrases with the 12.5 % compression ratio .", "label": "Evaluate For", "id": "train_1_23"}
{"text": "We relax the [[ non-linear nature ]] of the << problem >> by accepting two assumptions which surveillance scenarios offer , ie .", "label": "Feature Of", "id": "train_1_24"}
{"text": "Experimental results in the domain of face detection show the << training algorithm >> yields significant improvements in performance over conventional [[ AdaBoost ]] .", "label": "Compare", "id": "train_1_25"}
{"text": "A method of sense resolution is proposed that is based on WordNet , an on-line lexical database that incorporates << semantic relations >> -LRB- synonymy , antonymy , hyponymy , meronymy , [[ causal and troponymic entailment ]] -RRB- as labeled pointers between word senses .", "label": "Hypohym Of", "id": "train_1_26"}
{"text": "We study and compare two novel [[ embedding methods ]] for << segmenting feature points of piece-wise planar structures >> from two -LRB- uncalibrated -RRB- perspective images .", "label": "Used For", "id": "train_1_27"}
{"text": "Finally , a cross-corpus -LRB- and cross-language -RRB- experiment reveals better noise and reverberation robustness for [[ DOCCs ]] than for << MFCCs >> .", "label": "Compare", "id": "train_1_28"}
{"text": "In this paper , we present a novel [[ approach ]] to learn the << deep video representation >> by exploring both local and holistic contexts .", "label": "Used For", "id": "train_1_29"}
{"text": "A novel [[ evaluation scheme ]] is proposed which accounts for the effect of polysemy on the clusters , offering us a good insight into the potential and limitations of << semantically classifying undisambiguated SCF data >> .", "label": "Evaluate For", "id": "train_1_30"}
{"text": "Conventional << HMMs >> have [[ weak duration constraints ]] .", "label": "Feature Of", "id": "train_1_31"}
{"text": "We explore a variety of << predictive models >> , including Na \u00a8 \u0131ve Bayes mixture models and [[ mixtures of Markov models ]] , and report empirical evidence that MINPATH finds useful shortcuts that save substantial navigational effort .", "label": "Hypohym Of", "id": "train_1_32"}
{"text": "Our experiments show that punctuation is of little help in parsing spoken language and extracting [[ subcategorization cues ]] from << spoken language >> .", "label": "Part Of", "id": "train_1_33"}
{"text": "In this paper , we propose a novel algorithm to detect/compensate on-line interference effects when integrating [[ Global Navigation Satellite System -LRB- GNSS -RRB- ]] and << Inertial Navigation System -LRB- INS -RRB- >> .", "label": "Conjunction", "id": "train_1_34"}
{"text": "The [[ accuracy ]] of the << statistical method >> is reasonably good , comparable to taggers for English .", "label": "Evaluate For", "id": "train_1_35"}
{"text": "[[ It ]] also facilitates more efficient statistical ranking than a previous << approach >> to statistical generation .", "label": "Compare", "id": "train_1_36"}
{"text": "<< HBG >> incorporates [[ lexical , syntactic , semantic , and structural information ]] from the parse tree into the disambiguation process in a novel way .", "label": "Used For", "id": "train_1_37"}
{"text": "The grammar for this generator is designed to properly generate the << speaker 's intention >> in a [[ telephone dialogue ]] .", "label": "Feature Of", "id": "train_1_38"}
{"text": "Representing images with layers has many important << applications >> , such as [[ video compression ]] , motion analysis , and 3D scene analysis .", "label": "Hypohym Of", "id": "train_1_39"}
{"text": "Although the system performs well within a limited textual domain , further research is needed to make it effective for [[ open-domain question answering ]] and << text summarisation >> .", "label": "Conjunction", "id": "train_1_40"}
{"text": "We use a convex formulation of the multi-label Potts model with label costs and show that the [[ asymmetric map-uniqueness criterion ]] can be integrated into our << formulation >> by means of convex constraints .", "label": "Part Of", "id": "train_1_41"}
{"text": "[[ Wallflower ]] is shown to outperform previous << algorithms >> by handling a greater set of the difficult situations that can occur .", "label": "Compare", "id": "train_1_42"}
{"text": "[[ Deictic reference ]] and << feedback >> about the discourse are enabled .", "label": "Conjunction", "id": "train_1_43"}
{"text": "The system participated in all the tracks of the << segmentation bakeoff >> -- PK-open , PK-closed , AS-open , AS-closed , HK-open , HK-closed , MSR-open and [[ MSR - closed ]] -- and achieved the state-of-the-art performance in MSR-open , MSR-close and PK-open tracks .", "label": "Hypohym Of", "id": "train_1_44"}
{"text": "Our [[ approach ]] can handle the high intra-class variability and large proportion of << unrelated images >> returned by search engines .", "label": "Used For", "id": "train_1_45"}
{"text": "Our experiments demonstrate that the << induced model >> achieves significantly higher [[ accuracy ]] than a state-of-the-art coherence model .", "label": "Evaluate For", "id": "train_1_46"}
{"text": "They demonstrate a reduced drift and increased [[ robustness ]] to large << non-rigid deformations >> .", "label": "Feature Of", "id": "train_1_47"}
{"text": "In this paper , we describe the research using machine learning techniques to build a [[ comma checker ]] to be integrated in a << grammar checker >> for Basque .", "label": "Part Of", "id": "train_1_48"}
{"text": "This paper presents an approach to reliably extracting layers from images by taking advantages of the fact that homographies induced by [[ planar patches ]] in the << scene >> form a low dimensional linear subspace .", "label": "Part Of", "id": "train_1_49"}
{"text": "Furthermore , we show that the web data can improve [[ Term Error Rate Performance ]] by 3.8 % absolute and Maximum Term-Weighted Value in << Keyword Search >> by 0.0076-0 .1059 absolute points .", "label": "Evaluate For", "id": "train_1_50"}
{"text": "On this basis , we discuss the problems of [[ vagueness ]] and ambiguity in << semantic annotation >> .", "label": "Feature Of", "id": "train_1_51"}
{"text": "We provide a << logical definition of Minimalist grammars >> , that are [[ Stabler 's formalization of Chomsky 's minimalist program ]] .", "label": "Hypohym Of", "id": "train_1_52"}
{"text": "The classical MLE reestimation algorithms , namely the << forward-backward algorithm >> and the [[ segmental k-means algorithm ]] , are expanded and reestimation formulas are given for HMM with Gaussian mixture observation densities .", "label": "Conjunction", "id": "train_1_53"}
{"text": "We study the << number of hidden layers >> required by a multilayer neu-ral network with [[ threshold units ]] to compute a function f from n d to -LCB- O , I -RCB- .", "label": "Used For", "id": "train_1_54"}
{"text": "This mining procedure of AND and OR patterns is readily integrated to [[ boosting ]] , which improves the generalization ability over the conventional << boosting decision trees >> and boosting decision stumps .", "label": "Compare", "id": "train_1_55"}
{"text": "Ideally , these are basic vocabulary units suitable for different << tasks >> , such as speech and text understanding , [[ machine translation ]] , information retrieval , and statistical language modeling .", "label": "Hypohym Of", "id": "train_1_56"}
{"text": "In a motorized vehicle a number of easily measurable signals with frequency components related to the rotational speed of the engine can be found , e.g. , vibrations , [[ electrical system voltage level ]] , and << ambient sound >> .", "label": "Conjunction", "id": "train_1_57"}
{"text": "Experiments with the TREC 2003 and TREC 2004 QA tracks indicate that rankings produced by our metric correlate highly with official rankings , and that [[ POURPRE ]] outperforms direct application of existing << metrics >> .", "label": "Compare", "id": "train_1_58"}
{"text": "Our << model >> consists of multiple processing modules and a [[ hypothesis network ]] for quantitative integration of multiple sources of information .", "label": "Part Of", "id": "train_1_59"}
{"text": "Although Bikel 's parser achieves a higher accuracy for parsing written language , << it >> achieves a higher [[ accuracy ]] when extracting subcategorization cues from spoken language .", "label": "Evaluate For", "id": "train_1_60"}
{"text": "A unique characteristic of the system is its ability to cope with long-duration and complete occlusion without a [[ prior knowledge ]] about the << shape >> or motion of objects .", "label": "Feature Of", "id": "train_1_61"}
{"text": "From different reasons among which the speed of processing prevails << they >> are usually based on [[ dictionaries of word forms ]] instead of words .", "label": "Used For", "id": "train_1_62"}
{"text": "We introduce a new << interactive corpus exploration tool >> called [[ InfoMagnets ]] .", "label": "Hypohym Of", "id": "train_1_63"}
{"text": "The method allows a user to explore a model of syntax-based statistical machine translation -LRB- MT -RRB- , to understand the model 's strengths and weaknesses , and to compare [[ it ]] to other << MT systems >> .", "label": "Compare", "id": "train_1_64"}
{"text": "During decoding , we use a << block unigram model >> and a [[ word-based trigram language model ]] .", "label": "Conjunction", "id": "train_1_65"}
{"text": "This study compares the effect of noise and [[ reverberation ]] on << depression prediction >> using 1 -RRB- standard mel-frequency cepstral coefficients -LRB- MFCCs -RRB- , and 2 -RRB- features designed for noise robustness , damped oscillator cepstral coefficients -LRB- DOCCs -RRB- .", "label": "Feature Of", "id": "train_1_66"}
{"text": "Performance of each investigated << classifier >> is evaluated both via receiving operating curve and via a [[ measure ]] , called mean absolute error , related to the quality in predicting the corresponding word error rate .", "label": "Evaluate For", "id": "train_1_67"}
{"text": "Unlike evaluations in the SRE series , the << i-vector challenge >> was run entirely online and used fixed-length feature vectors projected into a [[ low-dimensional space -LRB- i-vectors -RRB- ]] rather than audio recordings .", "label": "Used For", "id": "train_1_68"}
{"text": "The board plugs directly into the [[ VME bus ]] of the << SUN4 >> , which controls the system and contains the natural language system and application back end .", "label": "Part Of", "id": "train_1_69"}
{"text": "In cross-domain learning , there is a more challenging problem that the domain divergence involves more than one dominant factors , e.g. , different [[ viewpoints ]] , various << resolutions >> and changing illuminations .", "label": "Conjunction", "id": "train_1_70"}
{"text": "This [[ topology ]] is then incorporated into the << Hidden Conditional Ordinal Random Field -LRB- H-CORF -RRB- framework >> for dynamic ordinal regression by constraining H-CORF parameters to lie on the ordinal manifold .", "label": "Part Of", "id": "train_1_71"}
{"text": "Experimental results demonstrate that the resulting registration process is more robust to missing low-level information as [[ it ]] favors << intensity correspondences >> statistically consistent with the learned intensity distributions .", "label": "Used For", "id": "train_1_72"}
{"text": "The [[ method ]] overcomes the limitations of conventional statistical methods which require large corpora to be effective , and << lexical approaches >> which depend on existing bilingual dictionaries .", "label": "Compare", "id": "train_1_73"}
{"text": "We apply the proposed method to a [[ speech-based information retrieval system ]] , which is a typical << IR system >> , and show that the method works well .", "label": "Hypohym Of", "id": "train_1_74"}
{"text": "We show that intrinsic image methods can be used to refine an initial , low-frequency shading estimate based on a << global lighting reconstruction >> from an original [[ texture and coarse scene geometry ]] in order to resolve the inherent global ambiguity in shading .", "label": "Feature Of", "id": "train_1_75"}
{"text": "<< Optimisation of the tree >> for non-sequential tracking , which minimises the errors in [[ temporal consistency ]] due to both the drift and the jumps , is proposed .", "label": "Evaluate For", "id": "train_1_76"}
{"text": "The operations are reduced to functions of a formal language , thus changing the level of abstraction of the [[ operations ]] to be performed on << SI-Nets >> .", "label": "Used For", "id": "train_1_77"}
{"text": "We demonstrate the effectiveness of our << approach >> on several tasks involving the discrimination of human gesture and motion categories , as well as on a [[ database of dynamic textures ]] .", "label": "Evaluate For", "id": "train_1_78"}
{"text": "However , due to the [[ linearity ]] of << PCA >> , non-linearities like rotations or independently moving sub-parts in the data can deteriorate the resulting model considerably .", "label": "Feature Of", "id": "train_1_79"}
{"text": "The model is designed for use in << error correction >> , with a focus on [[ post-processing ]] the output of black-box OCR systems in order to make it more useful for NLP tasks .", "label": "Part Of", "id": "train_1_80"}
{"text": "Specifically , this system is designed to deterministically choose between pronominalization , [[ superordinate substitution ]] , and << definite noun phrase reiteration >> .", "label": "Compare", "id": "train_1_81"}
{"text": "How to obtain << hierarchical relations >> -LRB- e.g. [[ superordinate - hyponym relation ]] , synonym relation -RRB- is one of the most important problems for thesaurus construction .", "label": "Hypohym Of", "id": "train_1_82"}
{"text": "It is based on : -LRB- 1 -RRB- an extended set of [[ features ]] ; and -LRB- 2 -RRB- << inductive decision tree learning >> .", "label": "Conjunction", "id": "train_1_83"}
{"text": "Furthermore , we introduce global variables in the model , which can represent << global properties >> such as translation , [[ scale ]] or viewpoint .", "label": "Hypohym Of", "id": "train_1_84"}
{"text": "Although the system performs well within a limited [[ textual domain ]] , further research is needed to make it effective for << open-domain question answering >> and text summarisation .", "label": "Compare", "id": "train_1_85"}
{"text": "With performance above 97 % accuracy for [[ newspaper text ]] , << part of speech -LRB- pos -RRB- tagging >> might be considered a solved problem .", "label": "Evaluate For", "id": "train_1_86"}
{"text": "In this paper , we present a << corpus-based supervised word sense disambiguation -LRB- WSD -RRB- system >> for Dutch which combines statistical classification -LRB- maximum entropy -RRB- with [[ linguistic information ]] .", "label": "Part Of", "id": "train_1_87"}
{"text": "Given two times observations , we formulate fine-grained change detection as a joint optimization problem of three related factors , i.e. , normal-aware lighting difference , [[ camera geometry correction flow ]] , and << real scene change mask >> .", "label": "Conjunction", "id": "train_1_88"}
{"text": "In particular , we explore the use of << probabilistic decision tree >> within the [[ clustering framework ]] to account for the variation as well as regularity in human created summaries .", "label": "Feature Of", "id": "train_1_89"}
{"text": "To further demonstrate its applications for computer vision , we apply it to learn a BN model for << facial Action Unit -LRB- AU -RRB- recognition >> from [[ real image data ]] .", "label": "Used For", "id": "train_1_90"}
{"text": "In opposition to the approach of Kamp and Rohrer the exact meaning of the tenses is fixed by the [[ resolution component ]] and not in the process of << syntactic analysis >> .", "label": "Compare", "id": "train_1_91"}
{"text": "Experiments were done for two << ag-glutinative and morphologically rich languages >> : [[ Finnish ]] and Turk-ish .", "label": "Hypohym Of", "id": "train_1_92"}
{"text": "The objective of this project is to develop a robust and high-performance speech recognition system using a [[ segment-based approach ]] to << phonetic recognition >> .", "label": "Used For", "id": "train_1_93"}
{"text": "The << recognition system >> will eventually be integrated with [[ natural language processing ]] to achieve spoken language understanding .", "label": "Conjunction", "id": "train_1_94"}
{"text": "In particular , << range concatenation languages -LSB- RCL -RSB- >> can be parsed in [[ polynomial time ]] and many classical grammatical formalisms can be translated into equivalent RCGs without increasing their worst-case parsing time complexity .", "label": "Feature Of", "id": "train_1_95"}
{"text": "We develop Wallflower , a << three-component system >> for background maintenance : the [[ pixel-level component ]] performs Wiener filtering to make probabilistic predictions of the expected background ; the region-level component fills in homogeneous regions of foreground objects ; and the frame-level component detects sudden , global changes in the image and swaps in better approximations of the background .", "label": "Part Of", "id": "train_1_96"}
{"text": "This is evident most compellingly by the very low [[ recognition rate ]] of all existing << face recognition systems >> when applied to live CCTV camera input .", "label": "Evaluate For", "id": "train_1_97"}
{"text": "We measured the quality of the paraphrases produced in an experiment , i.e. , -LRB- i -RRB- their grammaticality : at least 99 % correct sentences ; -LRB- ii -RRB- their equivalence in meaning : at least 96 % correct paraphrases either by meaning equivalence or entailment ; and , -LRB- iii -RRB- the amount of internal lexical and syntactical variation in a set of [[ paraphrases ]] : slightly superior to that of << hand-produced sets >> .", "label": "Compare", "id": "train_1_98"}
{"text": "Furthermore , the << maximum margin criterion >> , e.g. , [[ intra-class com-pactness ]] and inter-class penalty , on the output layer is imposed to seek more discriminative features across different domains .", "label": "Hypohym Of", "id": "train_1_99"}
{"text": "The [[ PDTB ]] is being built directly on top of the Penn TreeBank and Propbank , thus supporting the extraction of useful syntactic and semantic features and providing a richer substrate for the development and evaluation of << practical algorithms >> .", "label": "Evaluate For", "id": "train_1_100"}
{"text": "<< Synchronous dependency insertion grammars >> are a version of synchronous grammars defined on [[ dependency trees ]] .", "label": "Feature Of", "id": "train_1_101"}
{"text": "We show that intrinsic image methods can be used to refine an [[ initial , low-frequency shading estimate ]] based on a global lighting reconstruction from an original texture and coarse scene geometry in order to resolve the << inherent global ambiguity in shading >> .", "label": "Used For", "id": "train_1_102"}
{"text": "The [[ model ]] is embodied in a << program >> , APT , that can reproduce segments of actual tape-recorded descriptions , using organizational and discourse strategies derived through analysis of our corpus .", "label": "Part Of", "id": "train_1_103"}
{"text": "Results from experiments with word dependent substitution costs will demonstrate an additional increase of correlation between [[ automatic evaluation measures ]] and << human judgment >> .", "label": "Conjunction", "id": "train_1_104"}
{"text": "This in turn affects the [[ accuracy ]] of << word sense disambiguation -LRB- WSD -RRB- systems >> trained and applied on different domains .", "label": "Evaluate For", "id": "train_1_105"}
{"text": "For categorization task , [[ positive feature vectors ]] and << negative feature vectors >> are used cooperatively to construct generic , indicative summaries .", "label": "Conjunction", "id": "train_1_106"}
{"text": "A further reduction in the search space is achieved by using [[ semantic ]] rather than << syntactic categories >> on the terminal and non-terminal edges , thereby reducing the amount of ambiguity and thus the number of edges , since only edges with a valid semantic interpretation are ever introduced .", "label": "Compare", "id": "train_1_107"}
{"text": "This demonstrates << relighting >> with [[ reproduction of fine surface detail ]] .", "label": "Feature Of", "id": "train_1_108"}
{"text": "One is << string similarity >> based on [[ edit distance ]] .", "label": "Used For", "id": "train_1_109"}
{"text": "This paper presents our experience in planning and building [[ COMPLEX ]] , a << computational lexicon >> designed to be a repository of shared lexical information for use by Natural Language Processing -LRB- NLP -RRB- systems .", "label": "Hypohym Of", "id": "train_1_110"}
{"text": "This mining procedure of [[ AND and OR patterns ]] is readily integrated to << boosting >> , which improves the generalization ability over the conventional boosting decision trees and boosting decision stumps .", "label": "Part Of", "id": "train_1_111"}
{"text": "CriterionSM Online Essay Evaluation Service includes a capability that labels sentences in student writing with << essay-based discourse elements >> -LRB- e.g. , [[ thesis statements ]] -RRB- .", "label": "Hypohym Of", "id": "train_1_112"}
{"text": "We also find that the transcription errors inevitable in ASR output have a negative impact on [[ models ]] that combine << lexical-cohesion and conversational features >> , but do not change the general preference of approach for the two tasks .", "label": "Conjunction", "id": "train_1_113"}
{"text": "We present a << framework >> for word alignment based on [[ log-linear models ]] .", "label": "Used For", "id": "train_1_114"}
{"text": "Experiments with both synthetic and real data show that this new [[ algorithm ]] is faster , more accurate and more stable than existing << ones >> .", "label": "Compare", "id": "train_1_115"}
{"text": "Some of the << principles >> which are relevant to the topic of this paper are : -LRB- a -RRB- Multiple Layer of Grammars -LRB- b -RRB- Multiple Layer Presentation -LRB- c -RRB- Lexicon Driven Processing -LRB- d -RRB- [[ Form-Oriented Dictionary Description ]] .", "label": "Part Of", "id": "train_1_116"}
{"text": "To implement the two speech enhancement systems based on real-time VC , one from NAM to a whispered voice and the other from electrolaryngeal speech to a natural voice , we propose several << methods >> for reducing [[ computational cost ]] while preserving conversion accuracy .", "label": "Evaluate For", "id": "train_1_117"}
{"text": "We present the computational model for POS learning , and present results for applying it to << Bulgarian >> , a Slavic language with relatively [[ free word order ]] and rich morphology .", "label": "Feature Of", "id": "train_1_118"}
{"text": "This approach only requires a few common noun or pronoun seeds that correspond to the concept for the targeted << NE >> , e.g. he/she/man / woman for [[ PERSON NE ]] .", "label": "Hypohym Of", "id": "train_1_119"}
{"text": "When used as pre-training for action recognition , our method gives significant gains over << learning without external data >> on [[ benchmark datasets ]] like UCF101 and HMDB51 .", "label": "Evaluate For", "id": "train_1_120"}
{"text": "The application of the techniques to the [[ analysis of plant growth ]] , to << ocean surface microturbulence in IR image sequences >> , and to sediment transport is demonstrated .", "label": "Conjunction", "id": "train_1_121"}
{"text": "To further scale beyond this dataset , we propose a [[ semi-supervised learning framework ]] to expand the pool of << labeled data >> with high confidence predictions obtained from unlabeled data .", "label": "Used For", "id": "train_1_122"}
{"text": "A further reduction in the search space is achieved by using semantic rather than [[ syntactic categories ]] on the << terminal and non-terminal edges >> , thereby reducing the amount of ambiguity and thus the number of edges , since only edges with a valid semantic interpretation are ever introduced .", "label": "Feature Of", "id": "train_1_123"}
{"text": "The result shows that our [[ system ]] outperforms the << baseline system >> based on the IBM models in both translation speed and quality .", "label": "Compare", "id": "train_1_124"}
{"text": "In this paper , we propose a partially-blurred-image classification and analysis framework for automatically detecting << images >> containing [[ blurred regions ]] and recognizing the blur types for those regions without needing to perform blur kernel estimation and image deblurring .", "label": "Part Of", "id": "train_1_125"}
{"text": "In noisy conditions , the mismatch between corrupted speech signals and models trained on clean speech may cause the decoder to produce << word matches >> with [[ unrealistic durations ]] .", "label": "Feature Of", "id": "train_1_126"}
{"text": "Given a [[ single modal low-resolution face image ]] , we benefit from the multiple factor interactions of training tensor , and super-resolve its << high-resolution reconstructions >> across different modalities for face recognition .", "label": "Used For", "id": "train_1_127"}
{"text": "We compare two language modelling toolkits , the CMU and the SRI toolkit and arrive at three results : 1 -RRB- word-lemma based feature function models produce better results than token-based models , 2 -RRB- adding a [[ PoS-tag feature function ]] to the << word-lemma model >> improves the output and 3 -RRB- weights for lexical translations are suitable if the training material is similar to the texts to be translated .", "label": "Part Of", "id": "train_1_128"}
{"text": "We summarize the motivation for this effort , the goals , the implementation of a multi-site data collection paradigm , and the accomplishments of MADCOW in monitoring the collection and distribution of 12,000 utterances of [[ spontaneous speech ]] from five sites for use in a << multi-site common evaluation of speech , natural language and spoken language >> .", "label": "Evaluate For", "id": "train_1_129"}
{"text": "Or , -LRB- 2 -RRB- the context of the polysemous word will be used as a key to search a large corpus ; all words found to occur in that context will be noted ; WordNet will then be used to estimate the semantic distance from those words to the alternative senses of the polysemous word ; and that sense will be chosen that is closest in meaning to other words occurring in the same context If successful , this procedure could have practical applications to problems of [[ information retrieval ]] , << mechanical translation >> , intelligent tutoring systems , and elsewhere .", "label": "Conjunction", "id": "train_1_130"}
{"text": "First and most notably : standard << MFCC features >> suffer dramatically under test/train mismatch for both noise and reverberation ; [[ DOCC features ]] are far more robust .", "label": "Compare", "id": "train_1_131"}
{"text": "By extensive experiments , we show that our learned representation can significantly boost several << video recognition tasks >> -LRB- retrieval , classification , and [[ highlight detection ]] -RRB- over traditional video representations .", "label": "Hypohym Of", "id": "train_1_132"}
{"text": "We compare our [[ system ]] with 8 other << background subtraction algorithms >> .", "label": "Compare", "id": "train_1_133"}
{"text": "After introducing this approach to MT system design , and the basics of [[ monolingual UCG ]] , we will show how the << two >> can be integrated , and present an example from an implemented bi-directional English-Spanish fragment .", "label": "Hypohym Of", "id": "train_1_134"}
{"text": "For << mobile speech application >> , speaker DOA estimation accuracy , [[ interference robustness ]] and compact physical size are three key factors .", "label": "Feature Of", "id": "train_1_135"}
{"text": "In experiments using the Penn WSJ corpus , our automatically trained << model >> gave a performance of 86.6 % -LRB- [[ F1 ]] , sentences < 40 words -RRB- , which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection .", "label": "Evaluate For", "id": "train_1_136"}
{"text": "In this paper , we propose a [[ human action recognition system ]] suitable for << embedded computer vision applications >> in security systems , human-computer interaction and intelligent environments .", "label": "Used For", "id": "train_1_137"}
{"text": "The << demonstrator >> embodies an interesting combination of [[ hand-built , symbolic resources ]] and stochastic processes .", "label": "Part Of", "id": "train_1_138"}
{"text": "In this paper we examine a special subset of Verma constraints which are easy to understand , easy to identify and easy to apply ; they arise from '' [[ dormant independencies ]] , '' namely , << conditional independencies >> that hold in interventional distributions .", "label": "Conjunction", "id": "train_1_139"}
